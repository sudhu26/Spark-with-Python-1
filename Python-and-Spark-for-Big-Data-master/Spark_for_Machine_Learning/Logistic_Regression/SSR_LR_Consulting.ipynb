{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/shashank/spark-2.3.2-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('LR').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('customer_churn.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Names: string, Age: double, Total_Purchase: double, Account_Manager: int, Years: double, Num_Sites: double, Onboard_date: timestamp, Location: string, Company: string, Churn: int]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"FROM data SELECT *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|Churn|count(Names)|\n",
      "+-----+------------+\n",
      "|    1|         150|\n",
      "|    0|         750|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"FROM data SELECT Churn, COUNT(Names)  GROUP BY Churn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|             Company|count(Names)|\n",
      "+--------------------+------------+\n",
      "|Miller, Johnson a...|           1|\n",
      "|Hunter, Reyes and...|           1|\n",
      "|          Obrien PLC|           1|\n",
      "|            Soto PLC|           2|\n",
      "|            Todd LLC|           1|\n",
      "|Smith, Marshall a...|           1|\n",
      "|           Smith PLC|           1|\n",
      "|          Hall Group|           1|\n",
      "|Freeman, Lam and ...|           1|\n",
      "|       Smith-Carroll|           1|\n",
      "|Hall, Hernandez a...|           1|\n",
      "|          Cannon Inc|           1|\n",
      "|        White-Dennis|           1|\n",
      "|Wilson, Collins a...|           1|\n",
      "|Jennings, Gates a...|           1|\n",
      "|     Campbell-Willis|           1|\n",
      "|    Martinez-Roberts|           1|\n",
      "|        Robinson PLC|           1|\n",
      "|          Barton Inc|           1|\n",
      "|Hernandez, Middle...|           1|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"FROM data SELECT Company, COUNT(Names)  GROUP BY Company\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|              Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|\n",
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|   Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|\n",
      "|      Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|\n",
      "|        Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|\n",
      "|      Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|\n",
      "|     Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|\n",
      "|   Jessica Williams|48.0|      10356.02|              0| 5.12|      8.0|2009-03-03 23:13:37|6187 Olson Mounta...|        Kelly-Warren|    1|\n",
      "|        Eric Butler|44.0|      11331.58|              1| 5.23|     11.0|2016-12-05 03:35:43|4846 Savannah Roa...|   Reynolds-Sheppard|    1|\n",
      "|      Zachary Walsh|32.0|       9885.12|              1| 6.92|      9.0|2006-03-09 14:50:20|25271 Roy Express...|          Singh-Cole|    1|\n",
      "|        Ashlee Carr|43.0|       14062.6|              1| 5.46|     11.0|2011-09-29 05:47:23|3725 Caroline Str...|           Lopez PLC|    1|\n",
      "|     Jennifer Lynch|40.0|       8066.94|              1| 7.11|     11.0|2006-03-28 15:42:45|363 Sandra Lodge ...|       Reed-Martinez|    1|\n",
      "|       Paula Harris|30.0|      11575.37|              1| 5.22|      8.0|2016-11-13 13:13:01|Unit 8120 Box 916...|Briggs, Lamb and ...|    1|\n",
      "|     Bruce Phillips|45.0|       8771.02|              1| 6.64|     11.0|2015-05-28 12:14:03|Unit 1895 Box 094...|    Figueroa-Maynard|    1|\n",
      "|       Craig Garner|45.0|       8988.67|              1| 4.84|     11.0|2011-02-16 08:10:47|897 Kelley Overpa...|     Abbott-Thompson|    1|\n",
      "|       Nicole Olson|40.0|       8283.32|              1|  5.1|     13.0|2012-11-22 05:35:03|11488 Weaver Cape...|Smith, Kim and Ma...|    1|\n",
      "|     Harold Griffin|41.0|       6569.87|              1|  4.3|     11.0|2015-03-28 02:13:44|1774 Peter Row Ap...|Snyder, Lee and M...|    1|\n",
      "|       James Wright|38.0|      10494.82|              1| 6.81|     12.0|2015-07-22 08:38:40|45408 David Path ...|      Sanders-Pierce|    1|\n",
      "|      Doris Wilkins|45.0|       8213.41|              1| 7.35|     11.0|2006-09-03 06:13:55|28216 Wright Moun...|Andrews, Adams an...|    1|\n",
      "|Katherine Carpenter|43.0|      11226.88|              0| 8.08|     12.0|2006-10-22 04:42:38|Unit 4948 Box 481...|Morgan, Phillips ...|    1|\n",
      "|     Lindsay Martin|53.0|       5515.09|              0| 6.85|      8.0|2015-10-07 00:27:10|69203 Crosby Divi...|      Villanueva LLC|    1|\n",
      "|        Kathy Curry|46.0|        8046.4|              1| 5.69|      8.0|2014-11-06 23:47:14|9569 Caldwell Cre...|Berry, Orr and Ca...|    1|\n",
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"FROM data SELECT *\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string to date subset to relevant cols\n",
    "data2 = spark.sql(\"FROM data SELECT MONTH(TO_DATE(CAST(UNIX_TIMESTAMP(Onboard_date, 'MM/dd/yyyy') AS TIMESTAMP))) AS Month, \\\n",
    "            YEAR(TO_DATE(CAST(UNIX_TIMESTAMP(Onboard_date, 'MM/dd/yyyy') AS TIMESTAMP))) AS Year, \\\n",
    "          Age, Total_Purchase, Account_Manager, Years as Num_Years, Num_Sites, \\\n",
    "          SUBSTRING(SPLIT(Location, ',')[1], 0, 3) AS State, Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.createOrReplaceTempView('data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Num_Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+--------------+---------------+---------+---------+-----+-----+\n",
      "|Month|Year| Age|Total_Purchase|Account_Manager|Num_Years|Num_Sites|State|Churn|\n",
      "+-----+----+----+--------------+---------------+---------+---------+-----+-----+\n",
      "|    8|2013|42.0|       11066.8|              0|     7.22|      8.0|   AK|    1|\n",
      "|    8|2013|41.0|      11916.22|              0|      6.5|     11.0|   RI|    1|\n",
      "|    6|2016|38.0|      12884.75|              0|     6.67|     12.0|   DE|    1|\n",
      "|    4|2014|42.0|       8010.76|              0|     6.71|     10.0|   WY|    1|\n",
      "|    1|2016|37.0|       9191.58|              0|     5.56|      9.0|   MH|    1|\n",
      "|    3|2009|48.0|      10356.02|              0|     5.12|      8.0|   PR|    1|\n",
      "|   12|2016|44.0|      11331.58|              1|     5.23|     11.0|   IA|    1|\n",
      "|    3|2006|32.0|       9885.12|              1|     6.92|      9.0|   FM|    1|\n",
      "|    9|2011|43.0|       14062.6|              1|     5.46|     11.0|   MA|    1|\n",
      "|    3|2006|40.0|       8066.94|              1|     7.11|     11.0|   WI|    1|\n",
      "|   11|2016|30.0|      11575.37|              1|     5.22|      8.0| null|    1|\n",
      "|    5|2015|45.0|       8771.02|              1|     6.64|     11.0| null|    1|\n",
      "|    2|2011|45.0|       8988.67|              1|     4.84|     11.0|   AZ|    1|\n",
      "|   11|2012|40.0|       8283.32|              1|      5.1|     13.0|   WI|    1|\n",
      "|    3|2015|41.0|       6569.87|              1|      4.3|     11.0|   MT|    1|\n",
      "|    7|2015|38.0|      10494.82|              1|     6.81|     12.0|   HI|    1|\n",
      "|    9|2006|45.0|       8213.41|              1|     7.35|     11.0|   DE|    1|\n",
      "|   10|2006|43.0|      11226.88|              0|     8.08|     12.0| null|    1|\n",
      "|   10|2015|53.0|       5515.09|              0|     6.85|      8.0|   CO|    1|\n",
      "|   11|2014|46.0|        8046.4|              1|     5.69|      8.0|   RI|    1|\n",
      "+-----+----+----+--------------+---------------+---------+---------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|State|count(Churn)|\n",
      "+-----+------------+\n",
      "|   ME|          17|\n",
      "|   WA|          15|\n",
      "|   AL|          17|\n",
      "|   NM|          13|\n",
      "|   MI|          15|\n",
      "|   MH|          16|\n",
      "|   HI|          13|\n",
      "|   VT|           9|\n",
      "|   MO|           8|\n",
      "|   NE|          12|\n",
      "|   PW|          11|\n",
      "| null|          74|\n",
      "|   RI|          14|\n",
      "|   Bo|          33|\n",
      "|   NH|          15|\n",
      "|   AK|          16|\n",
      "|   AR|          17|\n",
      "|   PR|          15|\n",
      "|   AZ|          14|\n",
      "|   WV|          18|\n",
      "+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert location to state\n",
    "spark.sql(\"FROM data2 SELECT State , Count(Churn) GROUP BY State \").show() #74 Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = spark.sql (\"FROM data2 SELECT Month, Year, Age, Total_Purchase, Account_Manager, Num_Years, Num_Sites, \\\n",
    "                        COALESCE(State, 'Missing') AS State, Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index String\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_index = StringIndexer(inputCol='State', outputCol='State_ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot encoding\n",
    "State_encoder = OneHotEncoder(inputCol='State_ind', outputCol='StateVec')\n",
    "Month_encoder = OneHotEncoder(inputCol='Month', outputCol='MonthVec')\n",
    "Year_encoder = OneHotEncoder(inputCol='Year', outputCol='YearVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['MonthVec', 'YearVec', 'StateVec', 'Age', 'Total_Purchase', 'Account_Manager', \\\n",
    "                                      'Num_Years', 'Num_Sites'], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR Object\n",
    "lr_model = LogisticRegression(featuresCol='features', labelCol='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = [State_index, State_encoder, Month_encoder, Year_encoder, assembler, lr_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "train, test = data3.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6462462462462462"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = pipeline.fit(train)\n",
    "results = fit_model.transform(test)\n",
    "eval_results = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Churn')\n",
    "eval_results.evaluate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+--------------+---------------+---------+---------+-----+-----+\n",
      "|Month|Year| Age|Total_Purchase|Account_Manager|Num_Years|Num_Sites|State|Churn|\n",
      "+-----+----+----+--------------+---------------+---------+---------+-----+-----+\n",
      "|    8|2013|42.0|       11066.8|              0|     7.22|      8.0|   AK|    1|\n",
      "|    8|2013|41.0|      11916.22|              0|      6.5|     11.0|   RI|    1|\n",
      "|    6|2016|38.0|      12884.75|              0|     6.67|     12.0|   DE|    1|\n",
      "|    4|2014|42.0|       8010.76|              0|     6.71|     10.0|   WY|    1|\n",
      "|    1|2016|37.0|       9191.58|              0|     5.56|      9.0|   MH|    1|\n",
      "|    3|2009|48.0|      10356.02|              0|     5.12|      8.0|   PR|    1|\n",
      "|   12|2016|44.0|      11331.58|              1|     5.23|     11.0|   IA|    1|\n",
      "|    3|2006|32.0|       9885.12|              1|     6.92|      9.0|   FM|    1|\n",
      "|    9|2011|43.0|       14062.6|              1|     5.46|     11.0|   MA|    1|\n",
      "|    3|2006|40.0|       8066.94|              1|     7.11|     11.0|   WI|    1|\n",
      "|   11|2016|30.0|      11575.37|              1|     5.22|      8.0| null|    1|\n",
      "|    5|2015|45.0|       8771.02|              1|     6.64|     11.0| null|    1|\n",
      "|    2|2011|45.0|       8988.67|              1|     4.84|     11.0|   AZ|    1|\n",
      "|   11|2012|40.0|       8283.32|              1|      5.1|     13.0|   WI|    1|\n",
      "|    3|2015|41.0|       6569.87|              1|      4.3|     11.0|   MT|    1|\n",
      "|    7|2015|38.0|      10494.82|              1|     6.81|     12.0|   HI|    1|\n",
      "|    9|2006|45.0|       8213.41|              1|     7.35|     11.0|   DE|    1|\n",
      "|   10|2006|43.0|      11226.88|              0|     8.08|     12.0| null|    1|\n",
      "|   10|2015|53.0|       5515.09|              0|     6.85|      8.0|   CO|    1|\n",
      "|   11|2014|46.0|        8046.4|              1|     5.69|      8.0|   RI|    1|\n",
      "+-----+----+----+--------------+---------------+---------+---------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data2.select(['Month',\n",
    " 'Year',\n",
    " 'Age',\n",
    " 'Total_Purchase',\n",
    " 'Account_Manager',\n",
    " 'Num_Years',\n",
    " 'Num_Sites',\n",
    " 'State',\n",
    " 'Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = cols.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "train2, test2 = data4.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7134146341463415"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model2 = pipeline.fit(train2)\n",
    "results2 = fit_model2.transform(test2)\n",
    "eval_results2 = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Churn')\n",
    "eval_results2.evaluate(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that dropping NAs, instead of including them as \"Missing\" has a better prediction rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore params\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "family: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\n",
      "featuresCol: features column name. (default: features, current: features)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label, current: Churn)\n",
      "lowerBoundsOnCoefficients: The lower bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\n",
      "lowerBoundsOnIntercepts: The lower bounds on intercepts if fitting under bound constrained optimization. The bounds vector size must beequal with 1 for binomial regression, or the number oflasses for multinomial regression. (undefined)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "threshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "upperBoundsOnCoefficients: The upper bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\n",
      "upperBoundsOnIntercepts: The upper bounds on intercepts if fitting under bound constrained optimization. The bound vector size must be equal with 1 for binomial regression, or the number of classes for multinomial regression. (undefined)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(lr_model.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create param grid for cross validation\n",
    "paramGrid = (ParamGridBuilder().addGrid(lr_model.regParam, [0.01, 0.5, 2.0])\n",
    "             .addGrid(lr_model.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lr_model.maxIter, [1, 5, 10])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=eval_results2, numFolds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross validations\n",
    "cvModel = cv.fit(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cvModel.transform(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6383825417201541"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results2.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5750750750750752"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel = cv.fit(train)\n",
    "predictions = cvModel.transform(test)\n",
    "eval_results.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validated that dropping missing state observations is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = spark.read.csv('new_customers.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Month=8, Year=2013, Age=42.0, Total_Purchase=11066.8, Account_Manager=0, Num_Years=7.22, Num_Sites=8.0, State=' AK', Churn=1)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Names='Andrew Mccall', Age=37.0, Total_Purchase=9935.53, Account_Manager=1, Years=7.71, Num_Sites=8.0, Onboard_date=datetime.datetime(2011, 8, 29, 18, 37, 54), Location='38612 Johnny Stravenue Nataliebury, WI 15717-8316', Company='King Ltd')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.createOrReplaceTempView('pred_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data2 = spark.sql(\"FROM pred_data SELECT Names, Age, Total_Purchase, Account_Manager, Years AS Num_Years, Num_Sites, \\\n",
    "                        MONTH(TO_DATE(CAST(UNIX_TIMESTAMP(Onboard_date, 'MM/dd/yyyy') AS TIMESTAMP))) AS Month, \\\n",
    "                       YEAR(TO_DATE(CAST(UNIX_TIMESTAMP(Onboard_date, 'MM/dd/yyyy') AS TIMESTAMP))) AS Year, \\\n",
    "                       SUBSTRING(SPLIT(Location, ',')[1], 0, 3) AS State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+--------------+---------------+---------+---------+-----+----+-----+\n",
      "|         Names| Age|Total_Purchase|Account_Manager|Num_Years|Num_Sites|Month|Year|State|\n",
      "+--------------+----+--------------+---------------+---------+---------+-----+----+-----+\n",
      "| Andrew Mccall|37.0|       9935.53|              1|     7.71|      8.0|    8|2011|   WI|\n",
      "|Michele Wright|23.0|       7526.94|              1|     9.28|     15.0|    7|2013|   Yo|\n",
      "|  Jeremy Chang|65.0|         100.0|              1|      1.0|     15.0|   12|2006|   WY|\n",
      "|Megan Ferguson|32.0|        6487.5|              0|      9.4|     14.0|   10|2016|   NC|\n",
      "|  Taylor Young|32.0|      13147.71|              1|     10.0|      8.0|    3|2012| null|\n",
      "| Jessica Drake|22.0|       8445.26|              1|     3.46|     14.0|    2|2011| null|\n",
      "+--------------+----+--------------+---------------+---------+---------+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_data2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred_data = pred_data2.select(['Names','Month',\n",
    " 'Year',\n",
    " 'Age',\n",
    " 'Total_Purchase',\n",
    " 'Account_Manager',\n",
    " 'Num_Years',\n",
    " 'Num_Sites',\n",
    " 'State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data3 = cols_pred_data.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fit = pipeline.fit(data4)\n",
    "final_results = final_fit.transform(pred_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.createOrReplaceTempView('final_results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
